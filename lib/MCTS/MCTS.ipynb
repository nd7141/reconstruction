{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from pandas import DataFrame\n",
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from utils_mcts import ReplayBuffer, PathsBuffer, get_states_emb, convert_to_walk\n",
    "from MCTS import MCTS\n",
    "from problem_mcts import GraphProblem, generate_erdos_renyi_problems, generate_regular_problems\n",
    "from network_mcts import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')\n",
    "moving_average = lambda x, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(P, source, target):\n",
    "    '''Replace last occurrence of source with source-target-source.'''\n",
    "    assert source in P\n",
    "    ix = len(P) - P[::-1].index(source)\n",
    "    return P[:ix] + [target, P[ix - 1]] + P[ix:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covering_walk(graph, source):\n",
    "    P = [0]  # supporting walk\n",
    "    S = [0]  # stack of nodes to check\n",
    "    node2anon = {source: 0}\n",
    "    anon2node = {0: source}\n",
    "    checked = dict()  # nodes that has been checked for edge\n",
    "    degrees = graph.degree()\n",
    "    while len(S) > 0:  # grow supporting walk in DFS manner\n",
    "        curr = S[-1]\n",
    "        x = max(P) + 1  # next node to check\n",
    "\n",
    "        # check if there is a node in the neighborhood that has not been explored yet\n",
    "        Ncurr = list(nx.neighbors(graph, anon2node[curr]))\n",
    "        if random.uniform(0, 1) < 0.99:\n",
    "            random.shuffle(Ncurr)  # option 1: random order\n",
    "        else:\n",
    "            Ncurr = sorted(Ncurr, key=lambda v: degrees[v], reverse=True)  # option 2: top-degree\n",
    "            # Ncurr = sorted(Ncurr, key=lambda v: degrees[v], reverse=False)  # option 3: low-degree\n",
    "        # print(anon2node[curr], Ncurr)\n",
    "        for neighbor in Ncurr:\n",
    "            if neighbor in node2anon:\n",
    "                continue  # already visited\n",
    "            else:\n",
    "                node2anon[neighbor] = x\n",
    "                anon2node[x] = neighbor\n",
    "                S.append(x)\n",
    "                checked.setdefault(curr, set()).add(x)\n",
    "                P = replace(P, curr, x)  # move to it\n",
    "                break\n",
    "        else:\n",
    "            S.pop()  # move back in the stack\n",
    "\n",
    "        for u in range(x-1, curr, -1):  # u is already in the supporting walk\n",
    "            # check if there is connection to already discovered nodes\n",
    "            if u not in checked[curr]:  # see if we already checked this edge\n",
    "                if anon2node[u] in graph[anon2node[curr]]:\n",
    "                    P = replace(P, curr, u)\n",
    "                checked.setdefault(curr, set()).add(u)\n",
    "\n",
    "    cover = [anon2node[v] for v in P]\n",
    "    return cover, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "NUM_PROBLEMS = 20\n",
    "NUM_EPISODES = 10\n",
    "BATCH_SIZE = 32\n",
    "NUM_MCSIMS = 50\n",
    "NUM_UPDATES = 5\n",
    "NUM_VERTICES = 15\n",
    "DEGREE = 6\n",
    "CPUCT = 1.0\n",
    "THRESHOLD = 0.75\n",
    "PATHS_BUFFER_CAPACITY = 1000\n",
    "REPLAY_BUFFER_CAPACITY = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average = lambda x, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate regular train graphs (n=15, d=6)\n",
    "problem_maker = generate_regular_problems(num_vertices=NUM_VERTICES, degree=DEGREE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize agent\n",
    "agent = Agent(hid_size=256, gcn_size=256, vertex_emb_size=64, num_vertices=NUM_VERTICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize buffers\n",
    "path_buffer = PathsBuffer(capacity=PATHS_BUFFER_CAPACITY, threshold=THRESHOLD)\n",
    "train_buffer = ReplayBuffer(capacity=REPLAY_BUFFER_CAPACITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss stats\n",
    "pi_losses_history = []\n",
    "v_losses_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [next(problem_maker) for i in range(NUM_PROBLEMS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for iteration in trange(len(problems)):\n",
    "    \n",
    "    path_buffer.flush()\n",
    "    \n",
    "    problem = problems[iteration]\n",
    "    \n",
    "    for i in range(20):\n",
    "        cover, _ = covering_walk(problem.nx_graph, random.sample(list(problem.edges.keys()), 1)[0])\n",
    "        path_buffer.push(cover)\n",
    "    \n",
    "    path_length = 2*problem.num_edges+1\n",
    "    \n",
    "    for i in range(NUM_EPISODES):\n",
    "        \n",
    "        graph_emb = agent.embed_graph(problem.edges)\n",
    "    \n",
    "        problem.path = [random.sample(list(problem.edges.keys()), 1)[0]]\n",
    "        \n",
    "        mcts = MCTS(game=problem, nnet=agent, graph_emb=graph_emb,\n",
    "                    numMCTSSims=NUM_MCSIMS, cpuct=CPUCT, path_length=path_length)\n",
    "\n",
    "        trainExamples = []\n",
    "        \n",
    "        path = problem.get_state()\n",
    "        \n",
    "        while len(path) != path_length:\n",
    "            with torch.no_grad():\n",
    "                pi = mcts.getActionProb(path)\n",
    "            trainExamples.append([path, pi, None])\n",
    "            vertex = np.random.choice(len(pi), p=pi)\n",
    "            path = problem.get_next_state(path, vertex)\n",
    "        \n",
    "        path_buffer.push(path)\n",
    "        if len(path_buffer) >= 10: \n",
    "            r = path_buffer.rank_path(path)\n",
    "            for x in trainExamples:\n",
    "                x[-1] = r\n",
    "            train_buffer.push(trainExamples)\n",
    "            \n",
    "        if len(train_buffer) >= BATCH_SIZE:\n",
    "            for i in range(NUM_UPDATES):\n",
    "                batch = train_buffer.sample(BATCH_SIZE)\n",
    "                paths, pis, vs = zip(*batch)\n",
    "                embs = get_states_emb(paths, graph_emb)\n",
    "\n",
    "                target_pis = torch.FloatTensor(np.array(pis))\n",
    "\n",
    "                target_vs = torch.FloatTensor(np.array(vs).astype(np.float64))\n",
    "\n",
    "                out_pi, out_v = agent(embs)\n",
    "                loss_pi = -torch.sum(target_pis*out_pi)/target_pis.size()[0]\n",
    "                loss_v = torch.sum((target_vs-out_v.view(-1))**2)/target_vs.size()[0]\n",
    "                total_loss = loss_pi + loss_v\n",
    "\n",
    "                pi_losses_history.append(loss_pi.item())\n",
    "                v_losses_history.append(loss_v.item())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if iteration % 5 == 0:\n",
    "                    clear_output(True)\n",
    "                    plt.figure(figsize=[12, 6])\n",
    "                    plt.subplot(1,2,1)\n",
    "                    plt.title('Policy error'); plt.grid()\n",
    "                    plt.scatter(np.arange(len(pi_losses_history)), pi_losses_history, alpha=0.1)\n",
    "                    plt.plot(moving_average(pi_losses_history, span=100, min_periods=100))\n",
    "\n",
    "                    plt.subplot(1,2,2)\n",
    "                    plt.title('Value error'); plt.grid()\n",
    "                    plt.scatter(np.arange(len(v_losses_history)), v_losses_history, alpha=0.1)\n",
    "                    plt.plot(moving_average(v_losses_history, span=10, min_periods=10))\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_emb = agent.embed_graph(p.edges)\n",
    "path_length = 2*p.num_edges+1\n",
    "mcts = MCTS(game=p, nnet=agent, graph_emb=graph_emb,\n",
    "                    numMCTSSims=NUM_MCSIMS, cpuct=CPUCT, path_length=path_length)\n",
    "path = p.get_state()\n",
    "while len(path) != path_length:\n",
    "    with torch.no_grad():\n",
    "        pi = mcts.getActionProb(path)\n",
    "    vertex = np.random.choice(len(pi), p=pi)\n",
    "    path = p.get_next_state(path, vertex)\n",
    "print(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
