{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from pandas import DataFrame\n",
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from utils_mcts import ReplayBuffer, PathsBuffer, get_states_emb, convert_to_walk\n",
    "from MCTS_Act_LSTM import MCTS\n",
    "from problem_mcts import GraphProblem, generate_erdos_renyi_problems, generate_regular_problems\n",
    "from network_mcts import AgentActLSTM\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')\n",
    "moving_average = lambda x, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(P, source, target):\n",
    "    '''Replace last occurrence of source with source-target-source.'''\n",
    "    assert source in P\n",
    "    ix = len(P) - P[::-1].index(source)\n",
    "    return P[:ix] + [target, P[ix - 1]] + P[ix:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covering_walk(graph, source):\n",
    "    P = [0]  # supporting walk\n",
    "    S = [0]  # stack of nodes to check\n",
    "    node2anon = {source: 0}\n",
    "    anon2node = {0: source}\n",
    "    checked = dict()  # nodes that has been checked for edge\n",
    "    degrees = graph.degree()\n",
    "    while len(S) > 0:  # grow supporting walk in DFS manner\n",
    "        curr = S[-1]\n",
    "        x = max(P) + 1  # next node to check\n",
    "\n",
    "        # check if there is a node in the neighborhood that has not been explored yet\n",
    "        Ncurr = list(nx.neighbors(graph, anon2node[curr]))\n",
    "        if random.uniform(0, 1) < 0.99:\n",
    "            random.shuffle(Ncurr)  # option 1: random order\n",
    "        else:\n",
    "            Ncurr = sorted(Ncurr, key=lambda v: degrees[v], reverse=True)  # option 2: top-degree\n",
    "            # Ncurr = sorted(Ncurr, key=lambda v: degrees[v], reverse=False)  # option 3: low-degree\n",
    "        # print(anon2node[curr], Ncurr)\n",
    "        for neighbor in Ncurr:\n",
    "            if neighbor in node2anon:\n",
    "                continue  # already visited\n",
    "            else:\n",
    "                node2anon[neighbor] = x\n",
    "                anon2node[x] = neighbor\n",
    "                S.append(x)\n",
    "                checked.setdefault(curr, set()).add(x)\n",
    "                P = replace(P, curr, x)  # move to it\n",
    "                break\n",
    "        else:\n",
    "            S.pop()  # move back in the stack\n",
    "\n",
    "        for u in range(x-1, curr, -1):  # u is already in the supporting walk\n",
    "            # check if there is connection to already discovered nodes\n",
    "            if u not in checked[curr]:  # see if we already checked this edge\n",
    "                if anon2node[u] in graph[anon2node[curr]]:\n",
    "                    P = replace(P, curr, u)\n",
    "                checked.setdefault(curr, set()).add(u)\n",
    "\n",
    "    cover = [anon2node[v] for v in P]\n",
    "    return cover, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "NUM_PROBLEMS = 5\n",
    "NUM_EPISODES = 5\n",
    "BATCH_SIZE = 32\n",
    "NUM_MCSIMS = 10\n",
    "NUM_UPDATES = 5\n",
    "NUM_VERTICES = 15\n",
    "DEGREE = 6\n",
    "CPUCT = 1.0\n",
    "THRESHOLD = 0.75\n",
    "PATHS_BUFFER_CAPACITY = 1000\n",
    "REPLAY_BUFFER_CAPACITY = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average = lambda x, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate regular train graphs (n=15, d=6)\n",
    "problem_maker = generate_regular_problems(num_vertices=NUM_VERTICES, degree=DEGREE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize agent\n",
    "agent = AgentActLSTM(hid_size=256, gcn_size=256, vertex_emb_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize buffers\n",
    "path_buffer = PathsBuffer(capacity=PATHS_BUFFER_CAPACITY, threshold=THRESHOLD)\n",
    "train_buffer = ReplayBuffer(capacity=REPLAY_BUFFER_CAPACITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss stats\n",
    "pi_losses_history = []\n",
    "v_losses_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [next(problem_maker) for i in range(NUM_PROBLEMS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path built\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for k in trange(len(problems)):\n",
    "    \n",
    "    problem = problems[k]\n",
    "    \n",
    "    edges = problem.get_edges()\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(20):\n",
    "        cover, _ = covering_walk(problem.nx_graph, random.sample(list(problem.edges.keys()), 1)[0])\n",
    "        path_buffer.push(cover)\n",
    "    \"\"\"\n",
    "    \n",
    "    for vertex in problem.get_actions():\n",
    "        \n",
    "        path_buffer.flush()\n",
    "        \n",
    "        PATH_LENGTH = 2*problem.num_edges + 1        \n",
    "        \n",
    "        i += 1 \n",
    "    \n",
    "        for j in range(NUM_EPISODES):\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                graph_emb = agent.embed_graph(problem.edges)\n",
    "                \n",
    "            problem.path = [vertex]\n",
    "\n",
    "            path = problem.get_state()\n",
    "        \n",
    "            mcts = MCTS(game=problem, nnet=agent, graph_emb=graph_emb,\n",
    "                    numMCTSSims=NUM_MCSIMS, cpuct=CPUCT, edges=edges, path_length=PATH_LENGTH)\n",
    "\n",
    "            trainExamples = []\n",
    "        \n",
    "            while len(path) != PATH_LENGTH:\n",
    "                with torch.no_grad():\n",
    "                    pi = mcts.getActionProb(path, path_buffer)\n",
    "                trainExamples.append([path, pi, None])\n",
    "                \n",
    "                vertex = np.random.choice(edges[path[-1]], p=pi)\n",
    "                \n",
    "                path = problem.get_next_state(path, vertex)\n",
    "            print(\"Path built\")\n",
    "        \n",
    "            if len(path_buffer) >= 10: \n",
    "                r = path_buffer.rank_path(path)\n",
    "                for x in trainExamples:\n",
    "                    x[-1] = r\n",
    "                train_buffer.push(trainExamples)\n",
    "            \n",
    "            if len(train_buffer) >= BATCH_SIZE:\n",
    "                for i in range(NUM_UPDATES):\n",
    "                    batch = train_buffer.sample(BATCH_SIZE)\n",
    "                    paths, pis, vs = zip(*batch)\n",
    "                    graph_emb = agent.embed_graph(problem.edges)\n",
    "                    \n",
    "\n",
    "                    target_pis = torch.tensor(pis)\n",
    "\n",
    "                    target_vs = torch.tensor(vs)\n",
    "    \n",
    "                    out_pi, out_v = agent.get_dist(paths, graph_emb, edges)\n",
    "                    loss_pi = -torch.sum(target_pis*out_pi)/target_pis.size()[0]\n",
    "                    loss_v = torch.sum((target_vs-out_v.view(-1))**2)/target_vs.size()[0]\n",
    "                    total_loss = loss_pi + loss_v\n",
    "\n",
    "                    pi_losses_history.append(loss_pi.item())\n",
    "                    v_losses_history.append(loss_v.item())\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    total_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                clear_output(True)\n",
    "                plt.figure(figsize=[12, 6])\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.title('Policy error'); plt.grid()\n",
    "                plt.scatter(np.arange(len(pi_losses_history)), pi_losses_history, alpha=0.1)\n",
    "                plt.plot(moving_average(pi_losses_history, span=100, min_periods=100))\n",
    "    \n",
    "                plt.subplot(1,2,2)\n",
    "                plt.title('Value error'); plt.grid()\n",
    "                plt.scatter(np.arange(len(v_losses_history)), v_losses_history, alpha=0.1)\n",
    "                plt.plot(moving_average(v_losses_history, span=10, min_periods=10))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = problems[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.path = [random.sample(list(p.edges.keys()), 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_emb = agent.embed_graph(p.edges)\n",
    "path_length = 2*p.num_edges+1\n",
    "mcts = MCTS(game=p, nnet=agent, graph_emb=graph_emb,\n",
    "                    numMCTSSims=NUM_MCSIMS, cpuct=CPUCT, path_length=path_length)\n",
    "path = p.get_state()\n",
    "while len(path) != path_length:\n",
    "    with torch.no_grad():\n",
    "        pi = mcts.getActionProb(path)\n",
    "    vertex = np.random.choice(len(pi), p=pi)\n",
    "    path = p.get_next_state(path, vertex)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_buffer.buffer[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent, \"./agent.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = torch.load(\"./agent.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
